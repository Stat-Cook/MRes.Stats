<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="MRes.Stats">
<title>Module4_NullHypothesisSignificanceTesting • MRes.Stats</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Module4_NullHypothesisSignificanceTesting">
<meta property="og:description" content="MRes.Stats">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">MRes.Stats</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/CaseStudy1.html">Case Study 1</a>
    <a class="dropdown-item" href="../articles/CaseStudy1_Questions.html">CaseStudy1_Questions</a>
    <a class="dropdown-item" href="../articles/CaseStudy2_Questions.html">CaseStudy2_Questions</a>
    <a class="dropdown-item" href="../articles/CaseStudy3_Questions.html">CaseStudy3_Questions</a>
    <a class="dropdown-item" href="../articles/EducationalVideos.html">EducationalVideos</a>
    <a class="dropdown-item" href="../articles/EthicsviaTheTrolleyProblem.html">EthicsviaTheTrolleyProblem</a>
    <a class="dropdown-item" href="../articles/Frequentist_Bayesian.html">Frequentist_Bayesian</a>
    <a class="dropdown-item" href="../articles/MetaAnalysis.html">MetaAnalysis</a>
    <a class="dropdown-item" href="../articles/Module1_ScientificMethod.html">Module1_ScientificMethod</a>
    <a class="dropdown-item" href="../articles/Module2_DataTypes.html">Module2_DataTypes</a>
    <a class="dropdown-item" href="../articles/Module3_DescriptiveStatistics.html">Module3_DescriptiveStatistics</a>
    <a class="dropdown-item" href="../articles/Module4_NullHypothesisSignificanceTesting.html">Module4_NullHypothesisSignificanceTesting</a>
    <a class="dropdown-item" href="../articles/odds_risk_ratios.html">Risk and Odds Ratios</a>
    <a class="dropdown-item" href="../articles/Probability.html">Probability</a>
    <a class="dropdown-item" href="../articles/Probability_Questions.html">Probability_Questions</a>
    <a class="dropdown-item" href="../articles/SurveyDesign.html">SurveyDesign</a>
    <a class="dropdown-item" href="../articles/T-test_Primer.html">T-Test Primer</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Module4_NullHypothesisSignificanceTesting</h1>
            
      
      
      <div class="d-none name"><code>Module4_NullHypothesisSignificanceTesting.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In the first module, we discussed the concept of a hypothesis and
outlined the basic idea of aiming to disprove a hypothesis. The
framework came about due to the combination of two existing frameworks
for examining the results of experiments:</p>
<ul>
<li>the <em>Fisher</em> framework, which focused on the idea of a
<em>null hypothesis</em> and the probability of observing the data if
the null hypothesis were true; and</li>
<li>the <em>Neyman-Pearson</em> framework, which focused on the idea of
a <em>testable hypothesis</em> and the probability of observing the data
if the testable hypothesis were true.</li>
</ul>
<p>Now - these two frameworks were developed at roughly the same time as
each other, with the two academic camps being deeply sceptical of each
other’s work. Fisher, as an experimental scientist, developed the null
hypothesis framework from the perspective of ‘once data has been
collected, how do we test it’. His methods were designed to be used
after the data had been collected, and were focused on estimating the
probability of the data, if we assumed the null hypothesis were
true.</p>
<p>Neyman and Pearson, as theoretical mathematicians, developed their
testable hypothesis framework from the perspective of ‘how do we design
an experiment to test a hypothesis’.<br>
Their methods were designed to be used before the data had been
collected, and were focused on estimating the probability of the data,
under both the null and testable hypotheses.</p>
<p>Fisher introduced the concept that if a p-value (the ‘probability of
the data if our assumptions were true’) was smaller than 0.05 (5%), we
can conclude their is little ‘evidence’ in our data that the assumptions
were true. Neyman and Pearson (N&amp;P) expanded on this idea,
questioning what we could conclude not about our assumptions, but the
alternative to them, formalizing the concept of the <em>alternative
hypothesis</em> (the ‘something else’ that is occurring).</p>
<p>N&amp;P theorized that any experiment would be divided into two
possible outcomes - either the null hypothesis is true, or the
alternative hypothesis is true. Hence, the observations that have been
made would either support the null hypothesis or the alternative
hypothesis. The likelihood of the observations under each hypothesis
could be calculated, and the hypothesis with the higher likelihood would
be considered the more likely to be true.<br>
The statistician could set a threshold, e.g. 10 times more likely, at
which the null hypothesis would be rejected in favour of the alternative
hypothesis. In practice, this meant that the experimenter could derive a
<em>critical value</em> for the test statistic and if the observed test
statistic was greater than the critical value, the null hypothesis would
be rejected in favour of the alternative hypothesis.</p>
<p>Now - Fisher did not like this idea, and argued that i) the null
hypothesis should not be rejected, but rather that we should conclude
that there is insufficient evidence to support it and ii) that the
alternative hypothesis was unnecessary. Neyman and Pearson, however,
argued that the alternative hypothesis was necessary to provide a
framework for hypothesis testing, and that the null hypothesis should be
rejected in favour of the alternative hypothesis if the evidence
supported it.</p>
<p>While we can see this as splitting hairs, it was viewed as a
fundamental difference in approach to hypothesis testing. This makes our
current state confusing as <em>Null Hypothesis Significance Testing</em>
(NHST) is a combination of the two frameworks, aiming to take the best
of each while avoiding the worst of each.</p>
</div>
<div class="section level2">
<h2 id="null-hypothesis-significance-testing-nhst">Null Hypothesis Significance Testing (NHST)<a class="anchor" aria-label="anchor" href="#null-hypothesis-significance-testing-nhst"></a>
</h2>
<p>The framework begins with some hypothesis about the world, e.g. if we
wanted to check if a coin was ‘fair’:</p>
<blockquote>
<p>Null hypothesis: The coin is fair (i.e. <span class="math inline">\(P(Heads)  = 0.5\)</span>)</p>
</blockquote>
<p>and the alternative hypothesis:</p>
<blockquote>
<p>Alternative hypothesis: The coin is not fair (i.e. <span class="math inline">\(P(Heads)  != 0.5\)</span>)</p>
</blockquote>
<p>To collect data we can repeatedly toss the coin and count how often
we see heads.<br>
We need to know i) how many heads are too many/ too few and ii) how many
tosses do I need to make to be certain?</p>
<p>The key thought of NHST comes from observing the universe in two
ways:</p>
<ol style="list-style-type: decimal">
<li>as an all knowing Oracle</li>
<li>as an experimental scientist</li>
</ol>
<p>When these two viewpoints observe the same experiment the Oracle
knows with complete certainty if the null or alternative hypothesis is
true, while the scientist doesn’t. We hence have four possible
outcomes:</p>
<p><img src="../reference/figures/NHST_Outcomes.png"></p>
<p>The ‘Type I Error’ is when the experimental data suggests the null
hypothesis is incorrect when it was actually true (also known as a
<em>false positive</em>), and is essentially what we mean by
significant. When we say that a result is ‘significant’ at a 0.05 level,
we are concluding their is an effect and we are willing to accept a 5%
chance of making a Type I error, i.e. we are willing to accept a 5%
chance of rejecting the null hypothesis when it is actually true.</p>
<p>The ‘Type II Error’ is when the experimental data suggests the null
hypothesis is correct, when it was actually false (i.e. a <em>false
negative</em>) and is related to the concept of a studies
<strong>Power</strong> (how likely we are to find a given relationship
if it exists).<br>
If a study is powered at the 80% level, it means they believe the study
is able to detect (e.g. report a p-value below 0.05) the assumed
alternative hypothesis 8 times out of 10. The other 20% of the time the
study wouldn’t find the assumed behaviour, and hence at the design stage
they were happy to accept a 20% chance of making a Type II Error.</p>
<div class="section level3">
<h3 id="but-what-makes-a-p-value">But what makes a p-value?<a class="anchor" aria-label="anchor" href="#but-what-makes-a-p-value"></a>
</h3>
<p>A host of inferential tests exist for analysing data (t-test, <span class="math inline">\(\chi^2\)</span> test, ANOVA analysis etc) but they
all operate in a similar manner to produce a p-value. They begin by
deriving a model for the data <em>assuming the null hypothesis is
true</em>. Each test assumes a different set of hypothesis (e.g. the
Z-test assumes the data is normally distributed with a given mean) and
determines ‘how likely is it the observed data comes from this
model’.</p>
<p>Let’s think about this pictorially. We thought of the fair coin
earlier where our null hypothesis would be <span class="math inline">\(P(Heads) = 0.5\)</span>. If we were to toss a coin
100 times, we would expect to see:</p>
<p><img src="../reference/figures/NHST/HypotheticalCoin.png"></p>
<p>When the data has been collected we would see one of two outcomes -
either the tosses follow the hypothetical model:</p>
<div class="float">
<img src="../reference/figures/NHST/FairCoin.png" alt="Data follows the assumed model, so p-value is high"><div class="figcaption">Data follows the assumed model, so p-value is
high</div>
</div>
<p>or it deviates from it:</p>
<div class="float">
<img src="../reference/figures/NHST/BiasedCoin.png" alt="Data deviates from the assumed model, so p-value is low"><div class="figcaption">Data deviates from the assumed model, so p-value
is low</div>
</div>
<p>The data doesn’t have to perfectly follow the model, but large
deviations mean the data is unlikely to have come from the model, and so
the p-value is reduced.</p>
<p>In modern data analysis, a user wouldn’t be required to calculate a
p-value by hand and instead make use of a statistical package (e.g. R,
Python, SPSS) to calculate the p-value for them. What matters more is
understanding what the result means and the assumptions that underpin
the particular test statistic. Remember, a low p-value means that the
assumed distribution isn’t a good fit for the data, but this could be
any of the assumptions, not just your specific null hypothesis.</p>
</div>
<div class="section level3">
<h3 id="what-effects-the-power">What effects the power?<a class="anchor" aria-label="anchor" href="#what-effects-the-power"></a>
</h3>
<p>It may have come as a surprise that many studies are only powered at
an 80% level; going through all the struggle of data collection and
analysis, only to find that only 4 out of 5 times will the study find
the effect it is looking for.</p>
<p>You might wonder why don’t we power at 100%? Let’s take a look at the
idea of power in pictures and see if we can understand why this is the
case. The basic idea is to draw up our two hypotheses, e.g. if we were
testing if a new fetrilizer causes a better yield of crops, we might
have:</p>
<blockquote>
<p>Null hypothesis: The fertilizer has no effect on crop yield</p>
</blockquote>
<p>and</p>
<blockquote>
<p>Alternative hypothesis: The fertilizer has a positive effect on crop
yield</p>
</blockquote>
<p>Now, crop yield is not deterministic - there are some uncontrolled
factors that will affect the yield, alongside natural noise. Having
spoken with agricultural scientists, we might assume that the crops
without the new fertilizer have a mean yield between 75kg and 85kg.
Similarly, the crops with the fertilizer are expected to yield about 8kg
more. Pictorially - these assumption would look like this:</p>
<p><img src="../reference/figures/NHST/Power1.png"></p>
<p>So the power calculation asks ‘how many observations would I need
from the alternative hypothesis before I can be certain I’ll reject the
null hypothesis’. If we only take a few observations:</p>
<p><img src="../reference/figures/NHST/Power2.png"></p>
<p>There’s a chance they won’t be different from the null hypothesis.
But, as we take more and more:</p>
<p><img src="../reference/figures/NHST/Power3.png"></p>
<p>The distribution is more likely to be equally spread around the
alternative hypothesis, and so the chance of rejecting the null
hypothesis increases. The power is hence dependent on:</p>
<ol style="list-style-type: decimal">
<li>the number of observations</li>
<li>the size of the effect</li>
<li>the noise in the data.</li>
</ol>
<p>Let’s assume that we can’t change our experimental apparatus, so the
size of the effect and noise are constant. Now - the more observations
we have to make the more resource intensive the research is, and the
less ethical it may be (if we are exposing more participants to
risk).<br>
But - if we don’t observe enough participants for the study to be
properly powered, then the participants have been put at risk for no
benefit (deeply unethical).<br>
So the only control we have is the sample size, and there can be ethical
flaws to having too many or too few observations.</p>
</div>
<div class="section level3">
<h3 id="steps-beyond-nhst">Steps beyond NHST<a class="anchor" aria-label="anchor" href="#steps-beyond-nhst"></a>
</h3>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jane Doe.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
